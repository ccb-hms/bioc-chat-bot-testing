{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence_transformers polars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part1 (Sean Davis)\n",
    "## The problem\n",
    "\n",
    "We have a set of terms (sometimes multi-word) that represent a meaning. We want to map those terms to other terms from an ontology or controlled vocabulary, but we want to do so using their meaning, not just text matching. \"Encodings\" are a way of transforming words or sentences into vectors of numbers such that the points in N-dimensional space that are near each other have similar meanings. We use that idea here to map\n",
    "\n",
    "uncurated term ---> curated term\n",
    "\n",
    "We do this by:\n",
    "\n",
    "curated term ---> encodings\n",
    "\n",
    "uncurated term ---> encodings\n",
    "\n",
    "\n",
    "## Sentence transformers\n",
    "\n",
    "Sentence transformers refer to a type of natural language processing (NLP) model designed specifically for transforming sentences or text snippets into fixed-dimensional vectors, often with the goal of capturing semantic similarity. These models use deep learning techniques, typically employing architectures like Siamese networks or Transformer models.\n",
    "\n",
    "The primary objective of sentence transformers is to generate embeddings or representations of sentences in a way that the distance or similarity between these embeddings reflects the semantic meaning of the corresponding sentences. This makes them useful for various NLP tasks such as sentence similarity, clustering, and information retrieval.\n",
    "\n",
    "Commonly used architectures for sentence transformers include BERT (Bidirectional Encoder Representations from Transformers), RoBERTa (Robustly optimized BERT approach), and DistilBERT, among others. Pre-trained transformer models can be fine-tuned on specific tasks or datasets to create sentence embeddings tailored to a particular application.\n",
    "\n",
    "Sentence embeddings obtained from these models can be useful in a variety of applications, including semantic search, document retrieval, and sentiment analysis, where understanding the underlying semantic relationships between sentences is crucial.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5002643  -0.50500387 -0.47107634 ...  0.1224565   0.05091011\n",
      "   0.47183713]\n",
      " [-0.43048763 -0.16165991 -0.46010908 ...  0.10756782  0.16894086\n",
      "   0.5752676 ]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (29_340, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>curation_id</th><th>original_bodysite</th><th>curated_bodysite</th><th>curated_bodysite_ontology_term_id</th><th>curated_bodysite_source</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;acyc_fmi_2014:…</td><td>&quot;SALIVARY GLAND…</td><td>&quot;Salivary Gland…</td><td>&quot;NCIT:C12426&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;acyc_fmi_2014:…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;acyc_fmi_2014:…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;acyc_fmi_2014:…</td><td>&quot;BUCCAL MUCOSA&quot;</td><td>&quot;Buccal Mucosa&quot;</td><td>&quot;NCIT:C12505&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;acyc_fmi_2014:…</td><td>&quot;TUMOR EXTENTIO…</td><td>&quot;Bone&quot;</td><td>&quot;NCIT:C12366&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;luad_tcga_pan_…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;luad_tcga_pan_…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;luad_tcga_pan_…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;luad_tcga_pan_…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr><tr><td>&quot;luad_tcga_pan_…</td><td>&quot;LUNG&quot;</td><td>&quot;Lung&quot;</td><td>&quot;NCIT:C12468&quot;</td><td>&quot;TUMOR_TISSUE_S…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (29_340, 5)\n",
       "┌───────────────────┬───────────────────┬──────────────────┬───────────────────┬───────────────────┐\n",
       "│ curation_id       ┆ original_bodysite ┆ curated_bodysite ┆ curated_bodysite_ ┆ curated_bodysite_ │\n",
       "│ ---               ┆ ---               ┆ ---              ┆ ontology_term_i…  ┆ source            │\n",
       "│ str               ┆ str               ┆ str              ┆ ---               ┆ ---               │\n",
       "│                   ┆                   ┆                  ┆ str               ┆ str               │\n",
       "╞═══════════════════╪═══════════════════╪══════════════════╪═══════════════════╪═══════════════════╡\n",
       "│ acyc_fmi_2014:ACY ┆ SALIVARY GLAND    ┆ Salivary Gland   ┆ NCIT:C12426       ┆ TUMOR_TISSUE_SITE │\n",
       "│ C-FMI-01:ACYC-F…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ acyc_fmi_2014:ACY ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ C-FMI-02:ACYC-F…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ acyc_fmi_2014:ACY ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ C-FMI-03:ACYC-F…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ acyc_fmi_2014:ACY ┆ BUCCAL MUCOSA     ┆ Buccal Mucosa    ┆ NCIT:C12505       ┆ TUMOR_TISSUE_SITE │\n",
       "│ C-FMI-04:ACYC-F…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ acyc_fmi_2014:ACY ┆ TUMOR EXTENTION   ┆ Bone             ┆ NCIT:C12366       ┆ TUMOR_TISSUE_SITE │\n",
       "│ C-FMI-05:ACYC-F…  ┆ INTO BONE         ┆                  ┆                   ┆                   │\n",
       "│ …                 ┆ …                 ┆ …                ┆ …                 ┆ …                 │\n",
       "│ luad_tcga_pan_can ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ _atlas_2018:TCG…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ luad_tcga_pan_can ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ _atlas_2018:TCG…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ luad_tcga_pan_can ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ _atlas_2018:TCG…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ luad_tcga_pan_can ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ _atlas_2018:TCG…  ┆                   ┆                  ┆                   ┆                   │\n",
       "│ luad_tcga_pan_can ┆ LUNG              ┆ Lung             ┆ NCIT:C12468       ┆ TUMOR_TISSUE_SITE │\n",
       "│ _atlas_2018:TCG…  ┆                   ┆                  ┆                   ┆                   │\n",
       "└───────────────────┴───────────────────┴──────────────────┴───────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may need to adjust the URL to be the correct \"raw\" URL since this\n",
    "# uses a token. Your token may be different.\n",
    "df = pl.read_csv('https://github.com/cBioPortal/GSoC/files/14504294/curated_bodysite.csv')\n",
    "df.filter(pl.col('curated_bodysite') != \"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply filter out the rows where there is no curated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df = df.filter(df['curated_bodysite']!=\"NA\").select(['original_bodysite', 'curated_bodysite']).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we are creating a set of \"original\" (uncurated) values and a set of \"curated\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 'uncurated' results:  ['BRAIN STEM- PONS,BRAIN STEM-MEDULLA,CEREBELLUM/POSTERIOR FOSSA,SPINAL CORD- CERVICAL', 'DURA', 'OVARY', 'DIFFUSE', 'HEAD AND NECKREGIONAL LYMPH NODE', 'CNS', 'SMALL BOWEL MELANOMA', 'ABDOMEN/DIAPHRAGM', 'MEDIASTINAL', 'FRONTAL, PARIETAL AND TEMPORAL LOBE']\n",
      "first 'curated' results:  ['Pelvic Mass', 'Esophagus', 'Muscle', 'Right Lobe of the Liver', 'Axillary Lymph Node', 'Psoas Muscle', 'Greater Curvature of the Stomach', 'Urethra', 'Above', 'Perineum']\n"
     ]
    }
   ],
   "source": [
    "orig = []\n",
    "for x in filt_df['original_bodysite'].to_list():\n",
    "    orig.extend(x.split('<;>'))\n",
    "orig = list(set(orig))\n",
    "cura = []\n",
    "for x in filt_df['curated_bodysite'].to_list():\n",
    "    cura.extend(x.split('<;>'))\n",
    "cura = list(set(cura))\n",
    "print(\"first 'uncurated' results: \", orig[:10])\n",
    "print(\"first 'curated' results: \", cura[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to use the \"curated\" set, which corresponds to our controlled vocabulary or ontology terms, as a dictionary of sorts. We want to provide an index to that dictionary that allows us to look up words by **their meaning**. The emdeddings are the \"meaning\" and we can then use those as our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the curated results (which would, more generally, be the set of ontology terms of interest)\n",
    "cura_embed = model.encode(cura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "\n",
      "Query: BRAIN STEM- PONS,BRAIN STEM-MEDULLA,CEREBELLUM/POSTERIOR FOSSA,SPINAL CORD- CERVICAL\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Brain Stem (Score: 0.9223)\n",
      "    Cervical Spinal Cord (Score: 0.9196)\n",
      "    Brain (Score: 0.9081)\n",
      "    Central Nervous System (Score: 0.9038)\n",
      "    Cerebellum (Score: 0.9026)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: DURA\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Dura Mater (Score: 0.9757)\n",
      "    Spinal Cord Dura Mater (Score: 0.9354)\n",
      "    Skull (Score: 0.9081)\n",
      "    Skin (Score: 0.8967)\n",
      "    Meninges (Score: 0.8960)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: OVARY\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Ovary (Score: 1.0000)\n",
      "    Testis (Score: 0.9143)\n",
      "    Spleen (Score: 0.8985)\n",
      "    Uterus (Score: 0.8975)\n",
      "    Pancreas (Score: 0.8941)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: DIFFUSE\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Diffuse (Score: 1.0000)\n",
      "    Distant (Score: 0.8687)\n",
      "    Bilateral (Score: 0.8517)\n",
      "    Alveolar (Score: 0.8482)\n",
      "    Multifocal (Score: 0.8479)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: HEAD AND NECKREGIONAL LYMPH NODE\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Head and Neck (Score: 0.9410)\n",
      "    Regional Lymph Node (Score: 0.9312)\n",
      "    Lymph Node (Score: 0.9281)\n",
      "    Cervical Lymph Node (Score: 0.9256)\n",
      "    Supraclavicular Lymph Node (Score: 0.9200)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: CNS\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Central Nervous System (Score: 0.9511)\n",
      "    Brain (Score: 0.9194)\n",
      "    Cerebellum (Score: 0.9051)\n",
      "    Cerebral Cortex (Score: 0.9011)\n",
      "    Hypothalamus (Score: 0.9001)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: SMALL BOWEL MELANOMA\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Small Intestine (Score: 0.9327)\n",
      "    Small Intestine Resection (Score: 0.9178)\n",
      "    Intestine (Score: 0.8919)\n",
      "    Rectum (Score: 0.8800)\n",
      "    Colon (Score: 0.8739)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: ABDOMEN/DIAPHRAGM\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Abdomen (Score: 0.9638)\n",
      "    Diaphragm (Score: 0.9591)\n",
      "    Abdominal (Score: 0.9229)\n",
      "    Abdominal Wall (Score: 0.9168)\n",
      "    Right Upper Quadrant of Abdomen (Score: 0.9119)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: MEDIASTINAL\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Mediastinal (Score: 1.0000)\n",
      "    Mediastinum (Score: 0.9712)\n",
      "    Mediastinal Lymph Node (Score: 0.9520)\n",
      "    Anterior Mediastinum (Score: 0.9232)\n",
      "    Posterior Mediastinum (Score: 0.9217)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: FRONTAL, PARIETAL AND TEMPORAL LOBE\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Parietal Lobe (Score: 0.9479)\n",
      "    Temporal Lobe (Score: 0.9372)\n",
      "    Frontal Lobe (Score: 0.9357)\n",
      "    Parietal (Score: 0.9248)\n",
      "    Parieto-Occipital (Score: 0.9100)\n"
     ]
    }
   ],
   "source": [
    "# For the first 10 \"uncurated\" or \"original\" terms\n",
    "# 1. Embed term\n",
    "# 2. Find top 5 most similar vectors from curated term embeddings\n",
    "# 3. Report back the curated terms and scores\n",
    "\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "\n",
    "top_k = 5\n",
    "\n",
    "queries = orig[0:10]\n",
    "corpus = cura\n",
    "corpus_embeddings = cura_embed\n",
    "\n",
    "for query in queries:\n",
    "    # embed each uncurated term\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    # Seach in the corpus embeddings (the ontology terms that we embedded above)\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n======================\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Top 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(\"   \", corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary: `Sentence-transformer` [utils](https://www.sbert.net/docs/package_reference/util.html) has functions for cosine similarty, paraprase mining and semantic search.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2 (Tyrone Lee)\n",
    "We will attempt this query on the QA sample of 10 bioconductor support threads. The embedding model will differ from above because the source material is changed; instead of medical ontological terms, we are ingesting the top 10 questions and answers from [Bioconductor Forum](https://support.bioconductor.org/). Thought of using [codebert](https://huggingface.co/mchochlov/codebert-base-cd-ft) but it probably makes more sense to use the [multi-QA pretrained](https://www.sbert.net/docs/pretrained_models.html#multi-qa-models) encoders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.32228190e-02  1.49951935e-01  1.80716366e-02  6.45313561e-02\n",
      "   4.18474153e-03  5.07423542e-02  7.09168389e-02 -4.55774218e-02\n",
      "   5.10215089e-02 -2.57678218e-02  9.00099054e-02 -2.18730960e-02\n",
      "   8.43797326e-02 -6.58102110e-02 -2.66505815e-02 -8.88935402e-02\n",
      "   2.96451505e-02  2.01866925e-02 -3.38864475e-02 -1.30975619e-03\n",
      "   1.87437152e-04  3.30534726e-02  1.27255137e-03  3.21808569e-02\n",
      "  -3.58300023e-02 -2.87955329e-02  2.54739225e-02  5.04682250e-02\n",
      "   6.56116828e-02 -3.47291455e-02 -7.74945542e-02  1.40688559e-02\n",
      "  -2.01698691e-02  5.18850461e-02 -1.04643069e-02  5.99336214e-02\n",
      "   8.09594318e-02  9.55686420e-02 -4.56609093e-02  2.75027826e-02\n",
      "   9.46429092e-03 -8.58922303e-02  2.92307157e-02  3.21322978e-02\n",
      "   2.20695604e-02 -5.48757724e-02  4.88309227e-02 -3.58557813e-02\n",
      "  -1.37343332e-02 -1.08075269e-01 -6.05810471e-02 -1.38984695e-02\n",
      "  -8.91551301e-02  4.36695106e-02  1.58954635e-02  5.08062951e-02\n",
      "   1.40990159e-02  3.98281366e-02  6.52970513e-03 -4.16178852e-02\n",
      "   1.18416911e-02  2.81620473e-02 -2.20551863e-02  5.81702106e-02\n",
      "   1.49265945e-01 -1.98998898e-02  1.39007783e-02 -5.07267937e-02\n",
      "  -7.65035003e-02  3.71458232e-02  4.74058688e-02 -2.73936298e-02\n",
      "  -7.34869093e-02  2.37591192e-02 -1.07474074e-01 -2.23856885e-02\n",
      "  -2.77042892e-02 -1.39549617e-02  4.01059873e-02  5.15678548e-04\n",
      "  -6.11069575e-02 -9.83373448e-02 -3.93267609e-02 -5.48000596e-02\n",
      "   7.66592240e-03  4.84295785e-02 -9.84525308e-03 -1.59024477e-01\n",
      "   3.67113226e-03 -4.97747846e-02 -7.47939944e-02 -6.87319636e-02\n",
      "   2.65537272e-03  3.39435451e-02 -3.08669042e-02  2.44002491e-02\n",
      "  -9.65737626e-02 -2.04091966e-02 -2.44399700e-02  6.09576441e-02\n",
      "  -7.59862689e-03  1.26882894e-02  3.14376466e-02 -8.35463114e-04\n",
      "   1.24487849e-02 -1.03636310e-01 -2.27567907e-02 -9.17541012e-02\n",
      "   1.62204430e-02  1.49936918e-02 -4.35133949e-02 -4.08039279e-02\n",
      "  -1.38961598e-02  9.75814648e-03 -9.39971115e-03 -6.15535118e-02\n",
      "   2.24570427e-02 -3.88184853e-04 -8.71207267e-02  5.00588603e-02\n",
      "   8.06314647e-02 -7.38978991e-03 -5.60917296e-02  1.82107426e-02\n",
      "  -4.46246564e-02 -1.66155174e-02  9.30167455e-03  5.83260549e-31\n",
      "   2.78462935e-02 -7.59430677e-02  5.25545552e-02 -5.64638199e-03\n",
      "   7.91425556e-02  4.46953159e-03 -7.40387738e-02  3.81696075e-02\n",
      "  -2.61012353e-02  2.08707005e-02 -6.56913221e-03 -3.81465703e-02\n",
      "  -7.20908772e-03  3.14360783e-02 -2.78694835e-02 -2.33881474e-02\n",
      "  -3.13000455e-02  1.23140655e-01  7.11673722e-02 -1.65858474e-02\n",
      "  -7.09361359e-02  4.00983319e-02 -1.09536489e-02 -5.49892932e-02\n",
      "   2.54775658e-02  1.46327727e-02  5.06591238e-03 -4.56241071e-02\n",
      "  -4.35224455e-03  4.01888378e-02  1.00518519e-03  7.53492936e-02\n",
      "   6.46008179e-02  6.81621209e-02  7.42042288e-02  7.61511624e-02\n",
      "   6.97540790e-02 -2.24125814e-02  2.35551670e-02 -1.04030790e-02\n",
      "   1.20117366e-02 -1.60160959e-02  2.16776691e-02 -2.09560040e-02\n",
      "   2.44012084e-02 -1.53224639e-04  3.17460783e-02  8.24513286e-03\n",
      "  -1.20125920e-01  6.10916726e-02  5.37006892e-02  4.16471884e-02\n",
      "   7.70239681e-02 -1.96207948e-02  6.95023686e-02  2.38675140e-02\n",
      "   2.48863418e-02  1.24066412e-01 -7.35789612e-02 -3.21340561e-02\n",
      "  -6.13303818e-02  1.68775618e-02 -2.83910036e-02  3.47854607e-02\n",
      "  -6.13965541e-02  2.97728721e-02 -3.46969441e-03 -9.06743109e-02\n",
      "   3.78154293e-02 -3.15842107e-02 -5.11827432e-02  2.33317036e-02\n",
      "  -6.01878949e-02  5.71436062e-02 -5.19759282e-02 -7.05857389e-03\n",
      "  -5.51421121e-02 -6.86533898e-02 -5.60614951e-02  3.35808992e-02\n",
      "  -7.16875196e-02 -9.72534195e-02  2.69601475e-02 -9.13562812e-03\n",
      "  -5.73662817e-02  2.94641294e-02  2.18220185e-02 -1.09314166e-01\n",
      "   7.03127682e-02 -2.70084850e-02 -4.88789044e-02  3.92096204e-04\n",
      "   1.97783802e-02 -5.83278574e-02  4.60941978e-02 -3.13744071e-33\n",
      "  -2.46649124e-02  4.59635817e-03 -3.64865474e-02  7.49080023e-03\n",
      "   9.86847095e-04  3.38165089e-02  2.36792080e-02 -8.78112484e-03\n",
      "  -2.66713556e-02 -2.16805991e-02 -3.34284492e-02  2.56351079e-03\n",
      "   7.50883296e-02  4.06755740e-03  5.58185019e-03  1.09062409e-02\n",
      "   1.14430085e-01 -1.22063365e-02 -3.25768255e-02  6.46427423e-02\n",
      "  -2.74693035e-02  8.51673186e-02 -5.68316376e-04  1.33525962e-02\n",
      "  -5.95779717e-02  2.54754294e-02 -4.16278839e-02 -5.33928722e-02\n",
      "  -8.99888277e-02 -3.34609225e-02  3.26837413e-02  5.30601852e-03\n",
      "  -4.00202274e-02  1.66959073e-02 -1.10856555e-01  1.35031091e-02\n",
      "   3.16669717e-02 -8.60601813e-02 -1.33963348e-02  1.54581908e-02\n",
      "   1.50206909e-02 -2.33166162e-02  4.25483696e-02  9.82659087e-02\n",
      "   3.79490107e-02 -1.20836675e-01  5.24537042e-02 -9.44080129e-02\n",
      "  -2.17887368e-02  2.86350343e-02 -7.62880445e-02  2.48179194e-02\n",
      "  -2.01439541e-02  3.64070386e-02 -3.26878689e-02  2.05130177e-03\n",
      "   1.70349926e-02 -5.43478094e-02  3.34568471e-02 -2.80211028e-02\n",
      "  -1.57343782e-02  1.57294460e-02 -4.11463454e-02 -8.91587138e-03\n",
      "   1.08332478e-01 -3.86037081e-02 -5.89721352e-02  2.98092719e-02\n",
      "   4.34319302e-02  4.41885367e-02 -2.72072316e-03 -3.88302431e-02\n",
      "  -1.02429673e-01 -9.14919153e-02 -1.08352713e-01  3.48178782e-02\n",
      "   5.47246300e-02  1.83543637e-02 -7.33384639e-02 -4.56544496e-02\n",
      "   5.02667427e-02  4.16545459e-04 -4.48091142e-03  2.73227971e-03\n",
      "   3.47312330e-03 -7.62589946e-02 -2.77995504e-02 -2.93965191e-02\n",
      "  -1.26325516e-02  6.52823150e-02  2.12547630e-02 -1.03276521e-02\n",
      "   3.61310951e-02 -4.74747494e-02 -3.61633161e-03 -3.57529913e-33\n",
      "  -3.39566730e-02 -4.20515202e-02  4.74758446e-02 -2.56432574e-02\n",
      "   9.92499366e-02 -6.32043779e-02  5.59652559e-02 -5.82773425e-02\n",
      "  -1.35996630e-02 -1.20148053e-02  7.22979894e-03  9.60763022e-02\n",
      "  -1.96640994e-02  6.81429654e-02  4.64467630e-02  5.90089522e-02\n",
      "  -5.94835170e-02 -5.94847500e-02 -4.19475250e-02  5.06381355e-02\n",
      "   1.72817032e-03  3.55121642e-02 -2.39907149e-02 -1.34210894e-02\n",
      "   3.91660770e-03 -9.91139654e-03 -3.38950120e-02  2.29903287e-03\n",
      "   7.87032209e-03  8.19034204e-02  5.51250279e-02  8.63254964e-02\n",
      "   1.31356635e-03  9.92826372e-03 -3.14301290e-02  3.49846929e-02\n",
      "   7.22591653e-02  3.58433239e-02  1.16211278e-02 -1.04072012e-01\n",
      "   1.03914700e-02 -2.66558137e-02  4.49456610e-02  1.29606754e-01\n",
      "   6.94668666e-02  8.14684555e-02 -3.39856297e-02 -7.17377337e-03\n",
      "   6.48595486e-03  3.00916377e-02 -1.26871407e-01  3.93917225e-02\n",
      "   6.23512678e-02  1.20534943e-02  3.29195559e-02 -1.59236919e-02\n",
      "   8.29062313e-02 -1.27669964e-02 -5.53485490e-02 -4.19237139e-03\n",
      "  -8.64823163e-03  7.19451085e-02  7.33295754e-02  3.68165337e-02]\n",
      " [ 9.19859707e-02  1.05597869e-01  1.50556900e-02 -1.62263308e-02\n",
      "  -4.61816303e-02  4.78010848e-02  6.67928234e-02 -4.55253981e-02\n",
      "   8.15713555e-02  2.06049215e-02  7.04892725e-02 -6.40509138e-03\n",
      "   4.76659164e-02 -5.11251613e-02  3.71383987e-02  2.30572000e-03\n",
      "  -1.00737207e-01  1.29433334e-01 -1.00359127e-01 -2.46324688e-02\n",
      "  -2.73234211e-03  2.58272830e-02  1.06285559e-02  5.69388941e-02\n",
      "   1.07551143e-02  9.69487876e-02 -5.84471859e-02 -3.65805924e-02\n",
      "   1.71305258e-02 -4.94187810e-02 -9.57427025e-02  4.40210514e-02\n",
      "  -1.65107008e-02  1.79675464e-02  1.23839350e-02  2.74867900e-02\n",
      "   2.23172195e-02  2.63416581e-02  2.81917769e-02  1.64296627e-02\n",
      "   9.66485124e-03 -6.73861504e-02  2.87000593e-02 -4.87853680e-03\n",
      "   1.20917885e-02 -4.68726344e-02 -6.01092391e-02  3.35514247e-02\n",
      "   1.24536548e-02  2.61306763e-02 -3.15072984e-02  3.86755280e-02\n",
      "  -1.59542292e-01  8.67685601e-02 -2.67953034e-02  9.89865437e-02\n",
      "   4.04941337e-03  5.82031757e-02  4.71693873e-02 -6.75269738e-02\n",
      "  -8.01408961e-02  3.66632231e-02  1.93615593e-02  7.54064769e-02\n",
      "   6.76433891e-02 -6.69462159e-02  5.84847480e-03  1.05092190e-02\n",
      "  -9.44275558e-02  2.48986781e-02 -6.97429478e-02 -5.24516702e-02\n",
      "  -7.82662034e-02  1.87489465e-02 -4.77323402e-03  1.17982097e-03\n",
      "  -5.84291816e-02 -5.42685129e-02  7.38505498e-02  7.47144967e-03\n",
      "   2.33671460e-02 -5.57641648e-02 -4.59581427e-02 -4.96126935e-02\n",
      "   4.17287387e-02  1.72253381e-02 -1.02870129e-02 -1.46521211e-01\n",
      "  -1.25023704e-02 -2.43718196e-02 -6.26262203e-02 -1.54826701e-01\n",
      "   4.87310886e-02  5.49640432e-02 -5.72808273e-03 -1.91862360e-02\n",
      "  -9.86318365e-02 -1.47892097e-02  8.56946185e-02  7.02529326e-02\n",
      "  -3.17593776e-02  7.34847412e-02  3.41028236e-02 -1.19313248e-01\n",
      "  -1.34791777e-01 -9.05822366e-02  5.96718453e-02  1.58351548e-02\n",
      "  -4.93512535e-03 -1.56504791e-02 -1.95734967e-02  5.78621365e-02\n",
      "   6.63369671e-02  1.34147156e-03  1.15950834e-02  1.14095621e-02\n",
      "   8.30199197e-03 -4.62653749e-02 -2.88149696e-02  8.40303600e-02\n",
      "   3.42930220e-02  5.89356720e-02 -7.21880794e-03  6.75259680e-02\n",
      "  -9.66869444e-02 -5.73218167e-02  1.99208874e-02  8.39420516e-31\n",
      "  -2.88452376e-02 -1.66266318e-02  6.41841367e-02  4.91302572e-02\n",
      "  -7.53903016e-03  8.02553743e-02 -3.00223660e-02 -1.44390278e-02\n",
      "  -5.46987019e-02 -3.24112587e-02 -2.16944274e-02 -9.50158089e-02\n",
      "  -4.15172754e-03  5.22797778e-02  5.52392937e-03 -5.74093545e-03\n",
      "   5.99408383e-03  2.17502675e-04  5.09736948e-02  1.13442857e-02\n",
      "   3.67902145e-02  1.40378729e-01 -1.55291669e-02 -1.65548213e-02\n",
      "  -6.23418950e-02  3.63216549e-02 -7.90224504e-03 -1.95374563e-02\n",
      "  -2.25787815e-02 -8.05811491e-03 -7.58167952e-02  4.41279598e-02\n",
      "   6.17321730e-02  1.04060546e-02  3.48972417e-02 -2.58506294e-02\n",
      "   8.71366560e-02 -4.21810485e-02  6.16816767e-02 -3.37704681e-02\n",
      "  -1.14737697e-01  2.05461439e-02  6.25378117e-02  1.08917011e-02\n",
      "  -2.00458411e-02  1.23433597e-01  4.60247393e-04 -2.26016752e-02\n",
      "   3.46236564e-02  2.88246926e-02  2.06039334e-03  4.83396240e-02\n",
      "   5.36725298e-03  3.49997617e-02  2.90893055e-02  2.28833947e-02\n",
      "   4.76829819e-02  5.56845404e-02 -3.04503068e-02 -1.26053160e-02\n",
      "  -5.31505384e-02  9.40320548e-03 -4.27345186e-02 -2.44168267e-02\n",
      "   5.91291152e-02  9.55054630e-03  1.15279073e-03 -1.04474612e-01\n",
      "   1.73932761e-02 -2.77101970e-03 -1.20619006e-01 -5.77619858e-02\n",
      "  -1.78236689e-03  9.27243158e-02  2.72742510e-02 -1.50044216e-02\n",
      "  -1.59361027e-02 -6.25552610e-02 -3.32885236e-02 -5.20542217e-03\n",
      "  -7.66817555e-02  5.73098511e-02  3.13820988e-02 -8.20214748e-02\n",
      "   3.24842073e-02  7.15207821e-03  1.28829265e-02 -1.02320254e-01\n",
      "   9.91485566e-02  6.01926260e-03  5.64437546e-02 -3.70589271e-02\n",
      "   3.31301950e-02 -2.87779104e-02  2.44636014e-02 -2.13287407e-33\n",
      "  -3.74659449e-02  7.50246197e-02 -6.11342043e-02 -5.11543039e-05\n",
      "  -1.01623740e-02  2.04824805e-02 -1.00235511e-02  3.67665775e-02\n",
      "  -4.83441370e-04 -5.61728515e-03  4.15604678e-04 -3.75116915e-02\n",
      "   1.50174759e-02  2.35685240e-03 -2.92818323e-02  2.80762594e-02\n",
      "   1.16002440e-01  8.93003792e-02 -5.62598091e-03  1.28380889e-02\n",
      "   4.38958667e-02  8.28209072e-02 -1.51717914e-02 -1.21096503e-02\n",
      "  -9.81272850e-03 -2.41255183e-02  1.14931120e-03  2.77946088e-02\n",
      "  -2.19943132e-02  5.03603183e-02  4.63608876e-02 -2.57840380e-02\n",
      "  -5.37099279e-02  6.21599630e-02 -7.59643167e-02 -4.25162576e-02\n",
      "   4.04655598e-02 -9.45987832e-03 -6.36113286e-02  4.95661311e-02\n",
      "   3.68808024e-02 -5.84338158e-02 -5.41442074e-02 -1.33743659e-02\n",
      "   1.79119054e-02 -4.06523496e-02 -5.23437150e-02 -1.02629606e-02\n",
      "   2.33655144e-02 -1.52388131e-02  2.79896073e-02  4.51471880e-02\n",
      "  -8.04466903e-02 -5.48574328e-02  1.26540894e-02 -5.41529013e-03\n",
      "   4.11095768e-02 -1.02410838e-01 -2.08005658e-03 -3.34797651e-02\n",
      "  -4.40549999e-02  2.01391727e-02  1.69261787e-02 -8.57658759e-02\n",
      "   9.37013552e-02 -3.43258269e-02  2.21171416e-02  4.34981566e-03\n",
      "   3.32623571e-02  3.23079191e-02  1.13717588e-02 -2.41091102e-02\n",
      "  -7.04165995e-02  7.91718159e-03 -1.77426822e-02 -2.75665820e-02\n",
      "  -3.73401716e-02 -3.87267210e-03 -4.42389697e-02 -1.07363760e-02\n",
      "   5.32773845e-02 -3.13597508e-02 -8.27963930e-03  3.90430614e-02\n",
      "  -3.39305960e-02 -1.56444851e-02  1.13347501e-01  2.19109328e-03\n",
      "  -3.85909826e-02  4.87021431e-02  4.96798381e-03  4.06438345e-03\n",
      "   2.42505837e-02 -1.05060479e-02 -2.40305737e-02 -1.07707811e-33\n",
      "  -1.03950165e-01 -3.55654471e-02 -6.03964105e-02  8.92843679e-02\n",
      "  -1.99428070e-02  3.80828194e-02 -2.14842055e-02 -6.73012435e-02\n",
      "  -2.67349668e-02 -5.23411930e-02  3.18130925e-02  2.93458216e-02\n",
      "   3.53723355e-02 -3.52165066e-02  7.02063786e-03  1.03317991e-01\n",
      "  -4.72081080e-02 -1.49612688e-02 -1.39345787e-02 -2.68529188e-02\n",
      "  -4.96836891e-03  7.03044282e-03 -6.22066036e-02  4.25174050e-02\n",
      "   4.32606488e-02  1.09185139e-02 -2.88103446e-02  5.69733046e-02\n",
      "  -1.47488862e-02  3.20691541e-02  1.98536199e-02  2.15824079e-02\n",
      "   2.05124030e-03 -2.82409638e-02 -5.20581454e-02 -8.69514421e-02\n",
      "   8.76719803e-02 -2.78936941e-02  6.52893484e-02 -1.80080924e-02\n",
      "  -1.91009734e-02 -7.48036206e-02 -7.05686733e-02  7.57716447e-02\n",
      "  -3.86117212e-02 -5.20689078e-02 -3.30866501e-02 -2.97379550e-02\n",
      "   2.89045293e-02 -4.69843894e-02 -4.60865581e-03  4.38020118e-02\n",
      "   1.06454117e-03 -6.78221807e-02  1.09941110e-01 -4.20282707e-02\n",
      "   3.61388624e-02  6.45279586e-02 -1.39701378e-03  6.02438999e-03\n",
      "  -5.67142060e-03  7.01090619e-02  9.33586657e-02 -4.55023460e-02]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in csv with question and responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>AID</th><th>QID</th><th>Question</th><th>Response</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;answer1&quot;</td><td>&quot;question1&quot;</td><td>&quot;I am a bit con…</td><td>&quot;The thing to u…</td></tr><tr><td>&quot;answer2&quot;</td><td>&quot;question2&quot;</td><td>&quot;I am working o…</td><td>&quot;Just to be cle…</td></tr><tr><td>&quot;answer3&quot;</td><td>&quot;question3&quot;</td><td>&quot;I am new in th…</td><td>&quot;There is no go…</td></tr><tr><td>&quot;answer4&quot;</td><td>&quot;question4&quot;</td><td>&quot;I am testing s…</td><td>&quot;To answer your…</td></tr><tr><td>&quot;answer5&quot;</td><td>&quot;question5&quot;</td><td>&quot;In all RNA-seq…</td><td>&quot;The most compl…</td></tr><tr><td>&quot;answer6&quot;</td><td>&quot;question6&quot;</td><td>&quot;I know findOve…</td><td>&quot;From the discu…</td></tr><tr><td>&quot;answer7&quot;</td><td>&quot;question7&quot;</td><td>&quot;I have just do…</td><td>&quot;I wrote two he…</td></tr><tr><td>&quot;answer8&quot;</td><td>&quot;question8&quot;</td><td>&quot;How can I filt…</td><td>&quot;If you want to…</td></tr><tr><td>&quot;answer9&quot;</td><td>&quot;question9&quot;</td><td>&quot;I am analysing…</td><td>&quot;You can use th…</td></tr><tr><td>&quot;answer10&quot;</td><td>&quot;question10&quot;</td><td>&quot;How do I merge…</td><td>&quot;Merge is a pre…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 4)\n",
       "┌──────────┬────────────┬───────────────────────────────────┬───────────────────────────────────┐\n",
       "│ AID      ┆ QID        ┆ Question                          ┆ Response                          │\n",
       "│ ---      ┆ ---        ┆ ---                               ┆ ---                               │\n",
       "│ str      ┆ str        ┆ str                               ┆ str                               │\n",
       "╞══════════╪════════════╪═══════════════════════════════════╪═══════════════════════════════════╡\n",
       "│ answer1  ┆ question1  ┆ I am a bit confused about the co… ┆ The thing to understand is that … │\n",
       "│ answer2  ┆ question2  ┆ I am working on RNA-Seq data. I'… ┆ Just to be clear, there's an imp… │\n",
       "│ answer3  ┆ question3  ┆ I am new in this kind of analysi… ┆ There is no good way to do a DE … │\n",
       "│ answer4  ┆ question4  ┆ I am testing salmon and kallisto… ┆ To answer your questions:1) scal… │\n",
       "│ answer5  ┆ question5  ┆ In all RNA-seq analysis applicat… ┆ The most complete explanation of… │\n",
       "│ answer6  ┆ question6  ┆ I know findOverlaps() from Genom… ┆ From the discussion below, an ef… │\n",
       "│ answer7  ┆ question7  ┆ I have just downloaded CNV level… ┆ I wrote two helper functions, ex… │\n",
       "│ answer8  ┆ question8  ┆ How can I filter out the genes w… ┆ If you want to filter out genes … │\n",
       "│ answer9  ┆ question9  ┆ I am analysing my RNA-Seq data w… ┆ You can use the ensembldb packag… │\n",
       "│ answer10 ┆ question10 ┆ How do I merge a list of GRanges… ┆ Merge is a pretty vague term. My… │\n",
       "└──────────┴────────────┴───────────────────────────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv('bioc_qa.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first question:  ['question1'] ['I am a bit confused about the concepts of the 3 things: FDR, FDR adjusted p-value and q-value, which I initially thought I was clear about. Are FDR adjusted p-value the same as q-value? (my understanding is that FDR adjusted p-value = original p-value * number of genes/rank of the gene, is that right?) When people say xxx genes are differentially expressed with an FDR cutoff of 0.05, does that mean xxx genes have an FDR adjusted p-value smaller than 0.05?']\n",
      "first response:  ['answer1'] ['The thing to understand is that terms like FDR and q-value were defined in specific ways by their original inventors but are used in more generic ways by later researchers who adapt, modify or use the ideas.The term \"false discovery rate (FDR)\" was created by Benjamini and Hochberg in their 1995 paper. They gave a particular definition of what they meant by FDR.  Their procedure accepted or rejected hypotheses, but did not produce adjusted p-values.Benjamini and Yekutieli presented another more conservative algorithm to control the FDR in a 2001 paper. Same definition of FDR, but a different algorithm.In 2002, I re-interpreted the Benjamini and Hochberg (BH) and Benjamini and Yekutieli (BY) procedures in terms of adjusted p-values. I implemented the resulting algorithms in the function p.adjust() in the stats package, and used them in the limma package, and this lead to the concept of an FDR adjusted p-value. The terminology used by the p.adjust() function and limma packages has lead people to refer to \"BH adjusted p-values\".The adjusted p-value definition that you give is essentially the same as the BH adjusted p-value, except that you omitted the last step in the procedure. Your definition as it stands is not an increasing function of the original p-values.In 2002, John Storey created a new definition of \"false discovery rate\". Storey\\'s definition is based on Benjamini and Hochberg\\'s original idea, but is mathematically a bit more flexible. John Storey also created the terminology \"q-value\" for a quantity that estimates his definition of FDR. He implemented q-value estimation procedures in an R package called qvalue. Another important but often overlooked difference is the idea of FDR \"estimation\" vs FDR \"control\". The qvalue package attempts to give a more or less unbiased estimate of the FDR, so the true FDR is about equally likely to be greater or less in practice. The BH approach instead controls the expected FDR. It guarantees that the true FDR rate will be less than the specified rate on average if you do an exactly similar experiment over and over again. So the BH approach is slightly more conservative than qvalue. The BH properties hold regardless of the number of p-values, while qvalue is asymptotic, so the BH approach is more robust than qvalue when the number of hypotheses being tested isn\\'t very large.So, strictly speaking, the q-value and the FDR adjusted p-value are similar but not quite the same. However the terms q-value and FDR adjusted p-value are often used generically by the Bioconductor community to refer to any quantity that controls or estimates any definition of the FDR. In this general sense the terms are synonyms.The lesson to draw from this is that different methods and different packages are trying to do slighty different things and give slightly different results, and you should always cite the specific software and method that you have used.']\n"
     ]
    }
   ],
   "source": [
    "questions = df['Question'].to_list()\n",
    "answers = df['Response'].to_list()\n",
    "qID = df['QID'].to_list()\n",
    "aID = df['AID'].to_list()\n",
    "print(\"first question: \", qID[:1], questions[:1])\n",
    "print(\"first response: \", aID[:1], answers[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed ONLY the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the curated responses ('answers' in this case)\n",
    "ans_embed = model.encode(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same demo as above, only now we are giving queries that are not in the answer corpus. The demo will return the most similar text in corpus(the answers) to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "\n",
      "Query: I am a bit confused about the concepts of the 3 things: FDR, FDR adjusted p-value and q-value, which I initially thought I was clear about. Are FDR adjusted p-value the same as q-value? (my understanding is that FDR adjusted p-value = original p-value * number of genes/rank of the gene, is that right?) When people say xxx genes are differentially expressed with an FDR cutoff of 0.05, does that mean xxx genes have an FDR adjusted p-value smaller than 0.05?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    The thing to understand i (Score: 0.7044)\n",
      "    If you want to filter out (Score: 0.2630)\n",
      "    The most complete explana (Score: 0.2588)\n",
      "    You can use the ensembldb (Score: 0.2270)\n",
      "    To answer your questions: (Score: 0.2042)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am working on RNA-Seq data. I'm using DESeq2 for my analysis. I have 20 samples from 3 batches. I am testing for 2 conditions, cond1 and cond2.dds <- DESeqDataSetFromMatrix(countData = countTable3, colData = coldata, design = ~cond1 * cond2). When i performed PCA, I could clearly see some batch effect. I read in the forum that adding batch to the design in DESeq removes the batch effect. But I am not sure if this is the right way to go about it because I can still see the same batch effect dds <-DESeqDataSetFromMatrix(countData = countTable3, colData = coldata, design = ~batch+cond1*cond2) I tried using Combat but I'm unable to use combat results in DESeq. It gives me the following error.Error in DESeqDataSet(se, design = design, ignoreRank) : some values in assay are negative . I am not sure if removeBatchEffects() function can be used with DESeq. Can someone please help me out here.\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Just to be clear, there's (Score: 0.6995)\n",
      "    If you want to filter out (Score: 0.5211)\n",
      "    There is no good way to d (Score: 0.3662)\n",
      "    I wrote two helper functi (Score: 0.2222)\n",
      "    You can use the ensembldb (Score: 0.1880)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am new in this kind of analysis and I have a .csv file containing RNA-Seq data from different cell lines (with at least 3 replicates) normalised to TPM already, unfortunately I cannot access to the raw counts files.Is there a way I can follow to obtain the p-values, t-values and padj starting from TPM values in order to perform a differential expression analysis? I read about DESeq, DESeq2, EdgeR, limma and it looks like if all the R packages would ask for the raw counts and not from TPM values?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    There is no good way to d (Score: 0.6262)\n",
      "    To answer your questions: (Score: 0.3940)\n",
      "    If you want to filter out (Score: 0.3372)\n",
      "    The most complete explana (Score: 0.3228)\n",
      "    I wrote two helper functi (Score: 0.3061)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am testing salmon and kallisto for RNA-seq. Both tools output ESTIMATED counts and TPM.  My questions are: 1. from the help of tximport function:countsFromAbundance:character, either \"no\" (default), \"scaledTPM\", or \"lengthScaledTPM\", for whether to generate estimated counts using abundance estimates scaled up to library size (scaledTPM) or additionally scaled using the average transcript length over samples and the library size (lengthScaledTPM). if using scaledTPM or lengthScaledTPM, then the counts are no longer correlated with average transcript length, and so the length offset matrix should not be used.To my understanding, TPM is a unit that scaled by (effective) feature length first and then sequencing depth. So, what are scaledTPM and lengthScaled TPM? does tximport use the estimate counts to get the TPM? 2. what's the difference among the TPM output by salmon/kallisto and the TPM returned by tximport function? 3. How does tximport mathematically convert counts to TPM if use the estimated counts to get the TPM?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    To answer your questions: (Score: 0.8067)\n",
      "    There is no good way to d (Score: 0.5068)\n",
      "    The most complete explana (Score: 0.3076)\n",
      "    I wrote two helper functi (Score: 0.1593)\n",
      "    You can use the ensembldb (Score: 0.1502)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: In all RNA-seq analysis applications they talk about the dispersion of a gene. As far as I understood, it is not a variance of the normalized counts for a given gene. It is somehow much more complicated. But what would a dispersion of 0.19 or a dispersion of 0.80 tell me? Can I still interpret it as a variance of a gene?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    The most complete explana (Score: 0.6280)\n",
      "    If you want to filter out (Score: 0.2874)\n",
      "    To answer your questions: (Score: 0.2670)\n",
      "    There is no good way to d (Score: 0.2431)\n",
      "    You can use the ensembldb (Score: 0.1845)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I know findOverlaps() from GenomicRanges package does pretty good job for finding overlapped regions.I have studied whole vignette of GenomicRanges, BiocParallel pakages. findOverlaps function is very well done, but I need element wise operation across several GRanges objects simultaneously. I come up following reproducible example and put my desire output as well.Objective: find out overlapped regions across multiple GRanges objects simultanously (a.k.a, element-wise), aim to provide co-localization test and to save discarded enriched regions that was discarded in single trail, but discarded enriched regions will be saved by combining evidence of multiple Chip-seq experiment sample (find out its overlapped regions across across multiple GRanges objects in parallel). for example:Step 1: setuplibrary(GenomicRanges)a <- GRanges(  seqnames=Rle(c(\"chr1\", \"chr2\", \"chr3\", \"chr4\"), c(3, 2, 1, 2)),  ranges=IRanges(seq(1, by=5, len=8), seq(4, by=5, len=8)),  rangeName=letters[seq(1:8)],  score=sample(1:20, 8, replace = FALSE))b <- GRanges(  seqnames=Rle(c(\"chr1\", \"chr2\", \"chr3\",\"chr4\"), c(4, 1, 2, 1)),  ranges=IRanges(seq(2, by=6, len=8), seq(5, by=6, len=8)),  rangeName=letters[seq(1:8)],  score=sample(1:20, 8, replace = FALSE))c <- GRanges(  seqnames=Rle(c(\"chr1\", \"chr2\", \"chr3\",\"chr4\"), c(2, 4, 1,1)),   ranges=IRanges(seq(4, by=4, len=8), seq(7, by=4, len=8)),  rangeName=letters[seq(1:8)],  score=sample(1:15, 8, replace = FALSE))Step 2: I want to do overlap operation simultaneously such as:# each iteration, only take one ranges out of multiple ranges in# querySample (a.k.a, first GRanges objects)queryRange <- a[1]ov_b <- b[subjectHits(findOverlaps(a[1], b))]ov_c <- c[subjectHits(findOverlaps(a[1], c))]Step 3: then, I want to keep only one overlapped ranges from ov_b, ov_c (if there are multiple intersection were found), such as:ov_b_keepOne <- ov_b[which.max(ov_b$score)]  # if multiple overlapped                                             # found, only keep most                                             # significant one.ov_c_KeepOne <- ov_c[which.max(ov_c$score)]Step 4: then, use chisq.test to find out combined pvalue, such as:comb.pval <- chisq.test(c(queryRange$score, ov_b$score, ov_c$score))$p.valueStep 5: then, given threshold value gamma=1e-8,  (for example, comb.pvalue > gamma), then, execute below:res <- GRangesList('querySample'=queryRange,                   'targetSample_1'=ov_b_keepOne,                   'targetSample_2'=ov_c_KeepOne)Step 6: finally, this is my expected results :res.df <- as.data.frame(res)write.table(res.df, file=\"Confirmed.bed\")Objective: only take one ranges (a.k.a, each element of GRanges objects) out of multiple ranges, to find its overlapped ranges from multiple GRanges objects simultaneously (seems bplapply function can does this, but I haven't familiar with batch processing in R). I have bottleneck with this problem for a while, still not solved efficiently, any idea or possible approach to save my effort to efficiently develop my packages. Please point me out what should I do?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    I wrote two helper functi (Score: 0.6761)\n",
      "    From the discussion below (Score: 0.5432)\n",
      "    Merge is a pretty vague t (Score: 0.4233)\n",
      "    If you want to filter out (Score: 0.1671)\n",
      "    You can use the ensembldb (Score: 0.1638)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I have just downloaded CNV level 3 files from TCGA database. In these files there are three columns: chromosome, start, and end which presents the coordinates of genes. Now, I would like to map them to gene symbols, but I don't know. Can you tell me how to do that?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    You can use the ensembldb (Score: 0.4934)\n",
      "    I wrote two helper functi (Score: 0.3906)\n",
      "    If you want to filter out (Score: 0.1763)\n",
      "    To answer your questions: (Score: 0.1406)\n",
      "    Merge is a pretty vague t (Score: 0.1275)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: How can I filter out the genes with low read counts using DESeq2? Is this the right approach:dds<-DESEq(dt)count<-counts(dds,normalize=TRUE)filter<-rowsum(count)> 10\n",
      "Top 5 most similar sentences in corpus:\n",
      "    If you want to filter out (Score: 0.7972)\n",
      "    There is no good way to d (Score: 0.4235)\n",
      "    Just to be clear, there's (Score: 0.3770)\n",
      "    I wrote two helper functi (Score: 0.3691)\n",
      "    You can use the ensembldb (Score: 0.3643)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am analysing my RNA-Seq data with DESeq2. At the end I would like to convert significantly expressed  ensembl IDs to GeneSymbols. I am using AnnotationDbi for this. However, I realized that not all the ensembl IDs are converted to Gene Symbols. 25072 out of 48607 returned as NA. More than 11000 of these IDs are actually significantly differentially expressed .  So to double check, I put the IDs which got \"NA\" for Gene Symbol to Biomart and it converted them to Gene symbols. So now I am confused, am I doing something wrong ? Or is there any other alternative to extract all Gene symbols?\n",
      "Top 5 most similar sentences in corpus:\n",
      "    You can use the ensembldb (Score: 0.7109)\n",
      "    If you want to filter out (Score: 0.4806)\n",
      "    I wrote two helper functi (Score: 0.4169)\n",
      "    There is no good way to d (Score: 0.3514)\n",
      "    To answer your questions: (Score: 0.2378)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: How do I merge a list of GRanges? What I want is a GRanges object containing the union of all the ranges and the metadata in the list. I could loop over the list, taking the union of each pair of GRanges, but the union loses the metadata. Is there a way to merge all my GRanges into one giant GRanges, with metadata? What I ultimately want is a data.frame of counts so that I can input it into limma.\n",
      "Top 5 most similar sentences in corpus:\n",
      "    Merge is a pretty vague t (Score: 0.7294)\n",
      "    I wrote two helper functi (Score: 0.3030)\n",
      "    From the discussion below (Score: 0.1925)\n",
      "    There is no good way to d (Score: 0.1666)\n",
      "    To answer your questions: (Score: 0.1190)\n"
     ]
    }
   ],
   "source": [
    "# For the first 10 \"uncurated\" or \"original\" terms\n",
    "# 1. Embed term\n",
    "# 2. Find top 5 most similar vectors from curated term embeddings\n",
    "# 3. Report back the curated terms and scores\n",
    "\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "\n",
    "top_k = 5\n",
    "\n",
    "queries = questions[0:10]\n",
    "corpus = answers\n",
    "corpus_embeddings = ans_embed\n",
    "\n",
    "for query in queries:\n",
    "    # embed each uncurated term\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    # Seach in the corpus embeddings (the ontology terms that we embedded above)\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n======================\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Top 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(\"   \", corpus[idx][:25], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo prints the ID as a number in front of the answer, to check at a glance if most similar scoring answer is from the same row as the question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "\n",
      "Query: I am a bit confused about the concepts of the 3 things: FDR, FDR adjusted p-value and q-value, which I initially thought I was clear about. Are FDR adjusted p-value the same as q-value? (my understanding is that FDR adjusted p-value = original p-value * number of genes/rank of the gene, is that right?) When people say xxx genes are differentially expressed with an FDR cutoff of 0.05, does that mean xxx genes have an FDR adjusted p-value smaller than 0.05?\n",
      "ID: 0\n",
      "Top 5 most similar sentences in corpus:\n",
      "0 The thing to understand is that terms like FDR and (Score: 0.7044)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.2630)\n",
      "4 The most complete explanation of what the dispersi (Score: 0.2588)\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.2270)\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.2042)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am working on RNA-Seq data. I'm using DESeq2 for my analysis. I have 20 samples from 3 batches. I am testing for 2 conditions, cond1 and cond2.dds <- DESeqDataSetFromMatrix(countData = countTable3, colData = coldata, design = ~cond1 * cond2). When i performed PCA, I could clearly see some batch effect. I read in the forum that adding batch to the design in DESeq removes the batch effect. But I am not sure if this is the right way to go about it because I can still see the same batch effect dds <-DESeqDataSetFromMatrix(countData = countTable3, colData = coldata, design = ~batch+cond1*cond2) I tried using Combat but I'm unable to use combat results in DESeq. It gives me the following error.Error in DESeqDataSet(se, design = design, ignoreRank) : some values in assay are negative . I am not sure if removeBatchEffects() function can be used with DESeq. Can someone please help me out here.\n",
      "ID: 1\n",
      "Top 5 most similar sentences in corpus:\n",
      "1 Just to be clear, there's an important difference  (Score: 0.6995)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.5211)\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.3662)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.2222)\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.1880)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am new in this kind of analysis and I have a .csv file containing RNA-Seq data from different cell lines (with at least 3 replicates) normalised to TPM already, unfortunately I cannot access to the raw counts files.Is there a way I can follow to obtain the p-values, t-values and padj starting from TPM values in order to perform a differential expression analysis? I read about DESeq, DESeq2, EdgeR, limma and it looks like if all the R packages would ask for the raw counts and not from TPM values?\n",
      "ID: 2\n",
      "Top 5 most similar sentences in corpus:\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.6262)\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.3940)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.3372)\n",
      "4 The most complete explanation of what the dispersi (Score: 0.3228)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.3061)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am testing salmon and kallisto for RNA-seq. Both tools output ESTIMATED counts and TPM.  My questions are: 1. from the help of tximport function:countsFromAbundance:character, either \"no\" (default), \"scaledTPM\", or \"lengthScaledTPM\", for whether to generate estimated counts using abundance estimates scaled up to library size (scaledTPM) or additionally scaled using the average transcript length over samples and the library size (lengthScaledTPM). if using scaledTPM or lengthScaledTPM, then the counts are no longer correlated with average transcript length, and so the length offset matrix should not be used.To my understanding, TPM is a unit that scaled by (effective) feature length first and then sequencing depth. So, what are scaledTPM and lengthScaled TPM? does tximport use the estimate counts to get the TPM? 2. what's the difference among the TPM output by salmon/kallisto and the TPM returned by tximport function? 3. How does tximport mathematically convert counts to TPM if use the estimated counts to get the TPM?\n",
      "ID: 3\n",
      "Top 5 most similar sentences in corpus:\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.8067)\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.5068)\n",
      "4 The most complete explanation of what the dispersi (Score: 0.3076)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.1593)\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.1502)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: In all RNA-seq analysis applications they talk about the dispersion of a gene. As far as I understood, it is not a variance of the normalized counts for a given gene. It is somehow much more complicated. But what would a dispersion of 0.19 or a dispersion of 0.80 tell me? Can I still interpret it as a variance of a gene?\n",
      "ID: 4\n",
      "Top 5 most similar sentences in corpus:\n",
      "4 The most complete explanation of what the dispersi (Score: 0.6280)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.2874)\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.2670)\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.2431)\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.1845)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I know findOverlaps() from GenomicRanges package does pretty good job for finding overlapped regions.I have studied whole vignette of GenomicRanges, BiocParallel pakages. findOverlaps function is very well done, but I need element wise operation across several GRanges objects simultaneously. I come up following reproducible example and put my desire output as well.Objective: find out overlapped regions across multiple GRanges objects simultanously (a.k.a, element-wise), aim to provide co-localization test and to save discarded enriched regions that was discarded in single trail, but discarded enriched regions will be saved by combining evidence of multiple Chip-seq experiment sample (find out its overlapped regions across across multiple GRanges objects in parallel). for example:Step 1: setuplibrary(GenomicRanges)a <- GRanges(  seqnames=Rle(c(\"chr1\", \"chr2\", \"chr3\", \"chr4\"), c(3, 2, 1, 2)),  ranges=IRanges(seq(1, by=5, len=8), seq(4, by=5, len=8)),  rangeName=letters[seq(1:8)],  score=sample(1:20, 8, replace = FALSE))b <- GRanges(  seqnames=Rle(c(\"chr1\", \"chr2\", \"chr3\",\"chr4\"), c(4, 1, 2, 1)),  ranges=IRanges(seq(2, by=6, len=8), seq(5, by=6, len=8)),  rangeName=letters[seq(1:8)],  score=sample(1:20, 8, replace = FALSE))c <- GRanges(  seqnames=Rle(c(\"chr1\", \"chr2\", \"chr3\",\"chr4\"), c(2, 4, 1,1)),   ranges=IRanges(seq(4, by=4, len=8), seq(7, by=4, len=8)),  rangeName=letters[seq(1:8)],  score=sample(1:15, 8, replace = FALSE))Step 2: I want to do overlap operation simultaneously such as:# each iteration, only take one ranges out of multiple ranges in# querySample (a.k.a, first GRanges objects)queryRange <- a[1]ov_b <- b[subjectHits(findOverlaps(a[1], b))]ov_c <- c[subjectHits(findOverlaps(a[1], c))]Step 3: then, I want to keep only one overlapped ranges from ov_b, ov_c (if there are multiple intersection were found), such as:ov_b_keepOne <- ov_b[which.max(ov_b$score)]  # if multiple overlapped                                             # found, only keep most                                             # significant one.ov_c_KeepOne <- ov_c[which.max(ov_c$score)]Step 4: then, use chisq.test to find out combined pvalue, such as:comb.pval <- chisq.test(c(queryRange$score, ov_b$score, ov_c$score))$p.valueStep 5: then, given threshold value gamma=1e-8,  (for example, comb.pvalue > gamma), then, execute below:res <- GRangesList('querySample'=queryRange,                   'targetSample_1'=ov_b_keepOne,                   'targetSample_2'=ov_c_KeepOne)Step 6: finally, this is my expected results :res.df <- as.data.frame(res)write.table(res.df, file=\"Confirmed.bed\")Objective: only take one ranges (a.k.a, each element of GRanges objects) out of multiple ranges, to find its overlapped ranges from multiple GRanges objects simultaneously (seems bplapply function can does this, but I haven't familiar with batch processing in R). I have bottleneck with this problem for a while, still not solved efficiently, any idea or possible approach to save my effort to efficiently develop my packages. Please point me out what should I do?\n",
      "ID: 5\n",
      "Top 5 most similar sentences in corpus:\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.6761)\n",
      "5 From the discussion below, an efficient starting p (Score: 0.5432)\n",
      "9 Merge is a pretty vague term. My understanding is  (Score: 0.4233)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.1671)\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.1638)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I have just downloaded CNV level 3 files from TCGA database. In these files there are three columns: chromosome, start, and end which presents the coordinates of genes. Now, I would like to map them to gene symbols, but I don't know. Can you tell me how to do that?\n",
      "ID: 6\n",
      "Top 5 most similar sentences in corpus:\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.4934)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.3906)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.1763)\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.1406)\n",
      "9 Merge is a pretty vague term. My understanding is  (Score: 0.1275)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: How can I filter out the genes with low read counts using DESeq2? Is this the right approach:dds<-DESEq(dt)count<-counts(dds,normalize=TRUE)filter<-rowsum(count)> 10\n",
      "ID: 7\n",
      "Top 5 most similar sentences in corpus:\n",
      "7 If you want to filter out genes with low expressio (Score: 0.7972)\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.4235)\n",
      "1 Just to be clear, there's an important difference  (Score: 0.3770)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.3691)\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.3643)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: I am analysing my RNA-Seq data with DESeq2. At the end I would like to convert significantly expressed  ensembl IDs to GeneSymbols. I am using AnnotationDbi for this. However, I realized that not all the ensembl IDs are converted to Gene Symbols. 25072 out of 48607 returned as NA. More than 11000 of these IDs are actually significantly differentially expressed .  So to double check, I put the IDs which got \"NA\" for Gene Symbol to Biomart and it converted them to Gene symbols. So now I am confused, am I doing something wrong ? Or is there any other alternative to extract all Gene symbols?\n",
      "ID: 8\n",
      "Top 5 most similar sentences in corpus:\n",
      "8 You can use the ensembldb package to do the mappin (Score: 0.7109)\n",
      "7 If you want to filter out genes with low expressio (Score: 0.4806)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.4169)\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.3514)\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.2378)\n",
      "\n",
      "======================\n",
      "\n",
      "Query: How do I merge a list of GRanges? What I want is a GRanges object containing the union of all the ranges and the metadata in the list. I could loop over the list, taking the union of each pair of GRanges, but the union loses the metadata. Is there a way to merge all my GRanges into one giant GRanges, with metadata? What I ultimately want is a data.frame of counts so that I can input it into limma.\n",
      "ID: 9\n",
      "Top 5 most similar sentences in corpus:\n",
      "9 Merge is a pretty vague term. My understanding is  (Score: 0.7294)\n",
      "6 I wrote two helper functions, explained belowgeneR (Score: 0.3030)\n",
      "5 From the discussion below, an efficient starting p (Score: 0.1925)\n",
      "2 There is no good way to do a DE analysis of RNA-se (Score: 0.1666)\n",
      "3 To answer your questions:1) scaledTPM is TPM's sca (Score: 0.1190)\n"
     ]
    }
   ],
   "source": [
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "top_k = 5\n",
    "\n",
    "queries = questions[0:10]\n",
    "queryID = 0\n",
    "corpus = answers\n",
    "corpus_embeddings = ans_embed\n",
    "\n",
    "for query in queries:\n",
    "        query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "        print(\"\\n======================\\n\")\n",
    "        print(\"Query:\", query)\n",
    "        print(\"ID:\", queryID)\n",
    "        print(\"Top 5 most similar sentences in corpus:\")\n",
    "        queryID +=1\n",
    "\n",
    "        hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "        hits = hits[0]      #Get the hits for the first query\n",
    "        for hit in hits:\n",
    "            print(hit['corpus_id'],corpus[hit['corpus_id']][:50], \"(Score: {:.4f})\".format(hit['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated, cosine similarity seems \"good enough\" metric to evaluate if embedded documents match a given query. Trying to use this to compare answers given from an LLM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spotlight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
